## # 태깅 작업 개요

- 태깅작업은 지도학습이다. 
- X_train은 태깅을 하고자하는 단어가 되고, y_train(label)은 품사, 개체명등이 된다. 

<img src="https://user-images.githubusercontent.com/59716219/130390886-26ebecad-8414-4a20-a301-19340304b243.png" width="400" height="200">

- 각 데이터는 정수 인코딩 과정을 거친 후, 데이터의 길이를 맞춰주기 위해 패딩 작업을 거친다.
- 순환신경망의 many to many구조를 이용하여 예측을 출력한다. (여기서는 양방향 RNN을 사용한다)

<img src="https://user-images.githubusercontent.com/59716219/130390955-afce54aa-0af4-407f-a532-4ed5ea514877.png" width="400" height="250">

---

## # 개체명 인식, BIO 표현
> ### 개체명 인식
- 이름을 의미하는 단어를 보고 그 단어가 어떤 유형인지 인식하는 것
- ex) 유정이는 2018년에 골드만삭스에 입사했다. -> 유정 : 사람, 2018년 : 시간, 골드만삭스 : 조직
- NLTK에서는 개체명 인식기(NER chunker)를 지원하고 있다.
```python
from nltk import word_tokenize, pos_tag, ne_chunk
sentence = "James Disney London"
sentence=pos_tag(word_tokenize(sentence))
print(sentence) # 토큰화와 품사 태깅을 동시 수행
# [('James', 'NNP'), ('Disney', 'NNP'), ('London', 'NNP')]
sentence=ne_chunk(sentence)
print(sentence) # 개체명 인식
# (PERSON James/NNP), (ORGANIZATION Disney/NNP), (GPE London/NNP))
```

> ### BIO 표현

- B : Begin의 약자
- I : Inside의 약자
- O : outsize의 약자
- ex)
```python
해 B
리 I
포 I
터 I
보 O
러 O
가 O
자 O
```
- 영화 제목이 시작되는 '해'에서는 B가 사용되고, 영화 제목이 끝나는 순간까지 I가 사용된다. 영화 제목이 아닌 부분은 O가 사용된다. 
- B와 I는 개체명을 위해 사용되고, O는 개체명이 아니라는 의미를 갖게 된다. 
```python
해 B-movie
리 I-movie
포 I-movie
터 I-movie
보 O
러 O
메 B-theater
가 I-theater
박 I-theater
스 I-theater
가 O
자 O
```
- 각 개체가 어떤 종류인지도 태깅

---

## # F1 score

<img src="https://user-images.githubusercontent.com/59716219/130393215-bc25fad6-b0a7-4be8-bb01-68e637014348.png" width="600" height="450">

- 눈이 내릴지 아닐지를 예측하는 모델이 있을 때, 눈은 잘 내리지 않기때문에 모든값을 False로 예측한다면 정확도가 높은 모델을 얻을 수 있다. -> 문제
- recall(재현율) : 실제로 True인 데이터를 모델이 True라고 인식한 데이터의 수.
  - <img src="https://render.githubusercontent.com/render/math?math=TP\over{TP \dotplus FN}">
  - 그러나 모든 예측을 true라고 한다면 recall은 1이 된다. -> 문제
- Precision(정밀도) : 모델이 True로 예측한 데이터 중 실제로 True인 데이터의 수. 
  - <img src="https://render.githubusercontent.com/render/math?math=TP\over{TP \dotplus FP}">
  - 모델이 항상 눈이 내릴거라 예측하기 때문에 recall은 1이지만, 눈이 내리는 날은 많지 않아 낮은 precision을 가진다.
- Precision과 recall은 서로 trade-off되는 관계가 있다. 
- F1 score : precision과 recall의 조화평균
  - <img src="https://render.githubusercontent.com/render/math?math=2 * { {Precision * Recall} }\over {Precision \dotplus Recall}">

---

## # CRF(Conditional Random Field)

- 기존 양방향 LSTM 개체명 인식 모델
  - <img src="https://user-images.githubusercontent.com/59716219/130397072-0e3815e6-7ef6-4240-9b1c-36593b36c32f.png" width="400" height="250">
  - BIO표현에서는, 첫번째 단어의 레이블에서 i가 등장할 수 없다. 또한 I-per은 반드시 B-per뒤에서만 등장할 수 있다. 이런 BIO표현 방법의 제약사항들을 모두 위반하고 있다. 
- CRF층을 추가한다면 모델은 레이블 사이의 의존성을 고려할 수 있다. 
  - <img src="https://user-images.githubusercontent.com/59716219/130397313-be2053a6-3583-4ecd-8709-a8f3ffd0ac76.png" width="400" height="250">
  - <img src="https://render.githubusercontent.com/render/math?math=word_1">에 대한 BiLSTM 셀과 활성화 함수를 지난 출력값 [0.7, 0.12, 0.08, 0.04, 0.06]은 CRF 층의 입력이 된다.
  - CRF층은 점차적으로 훈련 데이터로부터 아래와 같은 제약사항등을 학습하게 된다. 
    1. 문장의 첫번째 단어에서는 I가 나오지 않는다.
    2. O-I 패턴은 나오지 않는다.
    3. B-I-I패턴에서 개쳅명은 일관성을 유지한다. (ex)B-Per다음에 I-Org는 나오지 않는다.)
- 양방향 LSTM은 입력 단어에 대한 양방향 문맥을 반영하며, CRF는 출력 레이블에 대한 양방향 문맥을 반영한다. 

---

## # 양방향 LSTM을 이용한 개체명 태깅 + CRF층 추가 
> 코드가 다른 파트와 겹치는 부분이 많아 해당 부분만 가져왔습니다.

> ### dataset 
<img src="https://user-images.githubusercontent.com/59716219/130400949-51630658-99fc-448a-91bc-0a807a61085f.png" width="300" height="150">

```python
data.isnull().values.any() # -> True
data.isnull().sum() # Sentence : 1000616
data = data.fillna(method="ffill") # Null값을 가진 행의 바로 앞의 행의 값으로 Null값을 채우는 함수
data['Word'] = data['Word'].str.lower() # 단어의 소문자화

#문장에 등장한 단어와 개체명 태깅 정보끼리 쌍으로 묶는 작업 수행
func = lambda temp: [(w, t) for w, t in zip(temp["Word"].values.tolist(), temp["Tag"].values.tolist())]
tagged_sentences=[t for t in data.groupby("Sentence #").apply(func)]
# tagged_sentences[0] : [('thousands', 'O'), ('of', 'O'), ('demonstrators', 'O'), ...]
# zip()함수를 이용하여 sentence와 개체명을 각각 리스트로 저장
sentences, ner_tags = [], [] 
for tagged_sentence in tagged_sentences: # 47,959개의 문장 샘플을 1개씩 불러온다.
    sentence, tag_info = zip(*tagged_sentence) # 각 샘플에서 단어들은 sentence에 개체명 태깅 정보들은 tag_info에 저장.
    sentences.append(list(sentence)) # 각 샘플에서 단어 정보만 저장한다.
    ner_tags.append(list(tag_info)) # 각 샘플에서 개체명 태깅 정보만 저장한다.
# sentences[98] : ['she', 'had', 'once', 'received', 'a', 'kidney', 'transplant', '.']
# ner_tags[98] : ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']

# 정수 인코딩
src_tokenizer = Tokenizer(oov_token='OOV') # 모든 단어를 사용하지만 인덱스 1에는 단어 'OOV'를 할당한다.
src_tokenizer.fit_on_texts(sentences)
tar_tokenizer = Tokenizer(lower=False) # 태깅 정보들은 내부적으로 대문자를 유지한채로 저장
tar_tokenizer.fit_on_texts(ner_tags)

vocab_size = len(src_tokenizer.word_index) + 1
tag_size = len(tar_tokenizer.word_index) + 1
#  src_tokenizer를 만들때 Tokenizer의 인자로 oov_token='OOV'를 선택했다. 이렇게 하면 인덱스1에 단어 'OOV'가 할당.

X_data = src_tokenizer.texts_to_sequences(sentences)
y_data = tar_tokenizer.texts_to_sequences(ner_tags)

# 결과 확인을 위해 인덱스로부터 단어를 리턴하는 index_to_word를 만듦
word_to_index = src_tokenizer.word_index
index_to_word = src_tokenizer.index_word
ner_to_index = tar_tokenizer.word_index
index_to_ner = tar_tokenizer.index_word
index_to_ner[0] = 'PAD'

# index_to_ner
# {1: 'O', 2: 'B-geo', 3: 'B-tim', 4: 'B-org', 5: 'I-per', 6: 'B-per', 7: 'I-org', 8: 'B-gpe', 9: 'I-geo', 10: 'I-tim', 11: 'B-art', 12: 'B-eve', 13: 'I-art', 14: 'I-eve', 15: 'B-nat', 16: 'I-gpe', 17: 'I-nat', 0: 'PAD'}

# padding
max_len = 70
# 모든 샘플들의 길이를 맞출 때 뒤의 공간에 숫자 0으로 채움.
X_data = pad_sequences(X_data, padding='post', maxlen=max_len)
y_data = pad_sequences(y_data, padding='post', maxlen=max_len)

# 훈련데이터와 테스트데이터 나누기
X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=.2, random_state=777)

# 원-핫 인코딩
y_train = to_categorical(y_train, num_classes=tag_size)
y_test = to_categorical(y_test, num_classes=tag_size)
```

> ### F1-score를 측정하는 콜백 클래스
```python
from keras.callbacks import Callback
from seqeval.metrics import f1_score, classification_report
# 이렇게 클래스를 구현해두면 모델을 검증 데이터를 통해 검증하는 과정에서 F1-score를 지속적으로 확인할 수 있다. 
# 그리고 F1-score가 높아질때마다 모델을 저장한다. 
class F1score(Callback):
    def __init__(self, value = 0.0, use_char=True):
        super(F1score, self).__init__()
        self.value = value
        self.use_char = use_char

    def sequences_to_tags(self, sequences): # 예측값을 index_to_ner를 사용하여 태깅 정보로 변경하는 함수.
      result = []
      for sequence in sequences: # 전체 시퀀스로부터 시퀀스를 하나씩 꺼낸다.
          tag = []
          for pred in sequence: # 시퀀스로부터 예측값을 하나씩 꺼낸다.
              pred_index = np.argmax(pred) # 예를 들어 [0, 0, 1, 0 ,0]라면 1의 인덱스인 2를 리턴한다.
              tag.append(index_to_ner[pred_index].replace("PAD", "O")) # 'PAD'는 'O'로 변경
          result.append(tag)
      return result

    # 에포크가 끝날 때마다 실행되는 함수
    def on_epoch_end(self, epoch, logs={}):

      # char Embedding을 사용하는 경우
      if self.use_char:
        X_test = self.validation_data[0]
        X_char_test = self.validation_data[1]
        y_test = self.validation_data[2]
        y_predicted = self.model.predict([X_test, X_char_test])

      else:
        X_test = self.validation_data[0]
        y_test = self.validation_data[1]
        y_predicted = self.model.predict([X_test])

      pred_tags = self.sequences_to_tags(y_predicted)
      test_tags = self.sequences_to_tags(y_test)

      score = f1_score(pred_tags, test_tags)
      print(' - f1: {:04.2f}'.format(score * 100))
      print(classification_report(test_tags, pred_tags))

      # F1-score가 지금까지 중 가장 높은 경우
      if score > self.value:
        print('f1_score improved from %f to %f, saving model to best_model.h5'%(self.value, score))
        self.model.save('best_model.h5')
        self.value = score
      else:
        print('f1_score did not improve from %f'%(self.value))
```

> ### BiLSTM을 이용한 개체명인식기
```python
from keras.models import Sequential
from keras.layers import Dense, LSTM, InputLayer, Bidirectional, TimeDistributed, Embedding
from keras.optimizers import Adam
from keras.models import load_model

model = Sequential()
model.add(Embedding(vocab_size, 128, input_length=max_len, mask_zero=True))
model.add(Bidirectional(LSTM(256, return_sequences=True)))
model.add(TimeDistributed(Dense(tag_size, activation=('softmax'))))
model.compile(loss='categorical_crossentropy', optimizer=Adam(0.001), metrics=['accuracy'])

history = model.fit(X_train, y_train, batch_size=32, epochs=10,  validation_split=0.1, callbacks=[F1score(use_char=False)])
bilstm_model = load_model('best_model.h5')

# predict
i=13 # 확인하고 싶은 테스트용 샘플의 인덱스.
y_predicted = bilstm_model.predict(np.array([X_test[i]])) # 입력한 테스트용 샘플에 대해서 예측 y를 리턴
y_predicted = np.argmax(y_predicted, axis=-1) # 원-핫 인코딩을 다시 정수 인코딩으로 변경함.
true = np.argmax(y_test[i], -1) # 원-핫 인코딩을 다시 정수 인코딩으로 변경함.

print("{:15}|{:5}|{}".format("단어", "실제값", "예측값"))
print(35 * "-")

for w, t, pred in zip(X_test[i], true, y_predicted[0]):
    if w != 0: # PAD값은 제외함.
        print("{:17}: {:7} {}".format(index_to_word[w], index_to_ner[t], index_to_ner[pred]))
 
단어             |실제값  |예측값
-----------------------------------
the              : O       O
statement        : O       O
came             : O       O
as               : O       O
u.n.             : B-org   B-org
secretary-general: I-org   I-org
kofi             : B-per   B-per
annan            : I-per   I-per
met              : O       O
with             : O       O
officials        : O       O
in               : O       O
amman            : B-geo   B-geo
to               : O       O
discuss          : O       O
wednesday        : B-tim   B-tim
's               : O       O
attacks          : O       O
.                : O       O
```
